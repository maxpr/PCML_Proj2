{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as sk\n",
    "from glove_routines import *\n",
    "from text_classifier import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 results found.\n",
      "27 small results found ( 1.5 threshold )\n",
      "Smallest lost for embeddings 5.0 is : 1202747.60121 with params: [5.0, 0.01, 1.0, 300.0, 1.0]\n",
      "   and name: embeddings_cost_emb5_eta0.01_alpha1_nmax300_epochs1.npy\n",
      "Smallest lost for embeddings 30.0 is : 2515917.23658 with params: [30.0, 0.01, 1.0, 300.0, 1.0]\n",
      "   and name: embeddings_cost_emb30_eta0.01_alpha1_nmax300_epochs1.npy\n",
      "Smallest lost for embeddings 50.0 is : 3791732.50916 with params: [50.0, 0.01, 1.0, 300.0, 1.0]\n",
      "   and name: embeddings_cost_emb50_eta0.01_alpha1_nmax300_epochs1.npy\n",
      "Smallest lost for embeddings 100.0 is : 1e+20 with params: [100.0, 0.01, 0.75, 150.0, 4.0]\n",
      "   and name: embeddings_cost_emb100_eta0.01_alpha0.75_nmax150_epochs4.npy\n",
      "Smallest lost for embeddings 100.0 is : 1e+20 with params: [100.0, 0.01, 0.75, 150.0, 4.0]\n",
      "   and name: embeddings_cost_emb100_eta0.01_alpha0.75_nmax150_epochs4.npy\n",
      "    [30.0, 0.01, 0.95, 200.0, 1.0]  loss is  1.49471430216\n",
      "    [30.0, 0.01, 0.95, 250.0, 1.0]  loss is  1.28251491382\n",
      "    [30.0, 0.01, 0.95, 300.0, 1.0]  loss is  1.0913854296\n",
      "    [30.0, 0.01, 0.9, 250.0, 1.0]  loss is  1.40684669869\n",
      "    [30.0, 0.01, 0.9, 300.0, 1.0]  loss is  1.25072507549\n",
      "    [30.0, 0.01, 1.0, 200.0, 1.0]  loss is  1.35901276268\n",
      "    [30.0, 0.01, 1.0, 250.0, 1.0]  loss is  1.1490872137\n",
      "    [30.0, 0.01, 1.0, 300.0, 1.0]  loss is  1.0\n",
      "    [50.0, 0.01, 0.95, 200.0, 1.0]  loss is  1.48425409446\n",
      "    [50.0, 0.01, 0.95, 250.0, 1.0]  loss is  1.24953059041\n",
      "    [50.0, 0.01, 0.95, 300.0, 1.0]  loss is  1.07632517028\n",
      "    [50.0, 0.01, 0.9, 250.0, 1.0]  loss is  1.41860463702\n",
      "    [50.0, 0.01, 0.9, 300.0, 1.0]  loss is  1.23550213098\n",
      "    [50.0, 0.01, 1.0, 200.0, 1.0]  loss is  1.3374044202\n",
      "    [50.0, 0.01, 1.0, 250.0, 1.0]  loss is  1.13761963643\n",
      "    [50.0, 0.01, 1.0, 300.0, 1.0]  loss is  1.0\n",
      "    [5.0, 0.001, 0.9, 200.0, 6.0]  loss is  1.49945567579\n",
      "    [5.0, 0.01, 0.95, 200.0, 1.0]  loss is  1.31728312486\n",
      "    [5.0, 0.01, 0.95, 250.0, 1.0]  loss is  1.19174004817\n",
      "    [5.0, 0.01, 0.95, 300.0, 1.0]  loss is  1.05645838687\n",
      "    [5.0, 0.01, 0.9, 200.0, 1.0]  loss is  1.46097701846\n",
      "    [5.0, 0.01, 0.9, 200.0, 4.0]  loss is  1.39586004457\n",
      "    [5.0, 0.01, 0.9, 250.0, 1.0]  loss is  1.22141299165\n",
      "    [5.0, 0.01, 0.9, 300.0, 1.0]  loss is  1.14889608587\n",
      "    [5.0, 0.01, 1.0, 200.0, 1.0]  loss is  1.27839725368\n",
      "    [5.0, 0.01, 1.0, 250.0, 1.0]  loss is  1.11094273837\n",
      "    [5.0, 0.01, 1.0, 300.0, 1.0]  loss is  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:40: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:41: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:42: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:48: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "C:\\Users\\andre\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:62: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def extrac_param(name):\n",
    "    params = []\n",
    "    splited = str(name).split(\"_\")\n",
    "    for i in range(2,np.shape(splited)[0]):\n",
    "        p = splited[i]\n",
    "        value = re.findall(r\"[+-]?\\d+(?:\\.\\d+)?\",p)\n",
    "        params.append(float(value[0]))\n",
    "    return params\n",
    "\n",
    "def choose_parameters(threshold):\n",
    "    '''\n",
    "    Test different parameters to see which one gives the better results.\n",
    "    '''\n",
    "    embedding_dim = [5, 30, 50, 100, 200]\n",
    "    for subdir, dirs, files in os.walk('metadata'):\n",
    "        size = np.shape(files)[0]\n",
    "        losses = np.zeros(size)\n",
    "        names = []\n",
    "        param = []\n",
    "        i=0\n",
    "        for file in files:\n",
    "            f = np.load('metadata/'+str(file))\n",
    "            losses[i] = f\n",
    "            names.append(file)\n",
    "            param.append(extrac_param(file))\n",
    "            i+=1\n",
    "    print(np.shape(names)[0], \"results found.\")\n",
    "    smallest_loss=np.ones(201)*pow(10,20)\n",
    "    smallest_idx = np.zeros(201)\n",
    "    small_lost = []\n",
    "    small_idx = []\n",
    "    small_lost_param = []\n",
    "    for i in range(0,np.shape(losses)[0]):\n",
    "        p = param[i]\n",
    "        emb = p[0]\n",
    "        loss = losses[i]\n",
    "        if(loss<smallest_loss[emb]):\n",
    "            smallest_loss[emb]=loss\n",
    "            smallest_idx[emb] = int(i)\n",
    "            \n",
    "    for i in range(0,np.shape(losses)[0]):\n",
    "        p = param[i]\n",
    "        emb = p[0]\n",
    "        loss = losses[i]\n",
    "        if(loss<threshold*smallest_loss[emb]):\n",
    "            small_lost.append(loss)\n",
    "            small_lost_param.append(p)\n",
    "            small_idx.append(i)\n",
    "\n",
    "    print(np.shape(small_lost)[0], \"small results found (\",threshold,\"threshold )\")\n",
    "\n",
    "    for i in embedding_dim:\n",
    "        cu_params = param[int(smallest_idx[i])]\n",
    "        print(\"Smallest lost for embeddings\",cu_params[0],\"is :\",smallest_loss[i],\"with params:\",cu_params)\n",
    "        print(\"   and name:\",names[int(smallest_idx[i])])\n",
    "    i=0\n",
    "    for a in small_idx:\n",
    "        p = param[a]\n",
    "        print(\"   \",param[a], \" loss is \", small_lost[i]/smallest_loss[p[0]])\n",
    "        i+=1\n",
    "choose_parameters(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings_emb100_eta0.01_alpha0.75_nmax150_epochs4.npy\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-509e27a31f05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     55\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m             \u001b[0mconstruct_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"embeddings/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-509e27a31f05>\u001b[0m in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32massert\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m             \u001b[0mconstruct_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"embeddings/\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def construct_features(embeddings_file=\"data/embeddings.npy\", flag_save=\"\"):\n",
    "    '''\n",
    "    construct a feature representation of each training tweet \n",
    "    (by averaging the word vectors over all words of the tweet).\n",
    "    '''\n",
    "    #Load the training tweets and the built GloVe word embeddings.\n",
    "    pos_train = open('data/pos_train.txt').readlines()\n",
    "    neg_train = open('data/neg_train.txt').readlines()\n",
    "    embeddings = np.load(embeddings_file)\n",
    "\n",
    "    \n",
    "    #count number of word/tweet and store it\n",
    "    word_nbr_per_tweet_pos = np.zeros(np.shape(pos_train)[0])\n",
    "    for j in range(0,np.shape(pos_train)[0]):\n",
    "        tweet = pos_train[j]\n",
    "        size = len(re.findall(r'\\w+', tweet))\n",
    "        word_nbr_per_tweet_pos[j] = size\n",
    "        \n",
    "    word_nbr_per_tweet_neg = np.zeros(np.shape(neg_train)[0])\n",
    "    for j in range(0,np.shape(neg_train)[0]):\n",
    "        tweet = neg_train[j]\n",
    "        size = len(re.findall(r'\\w+', tweet))\n",
    "        word_nbr_per_tweet_neg[j] = size\n",
    "    \n",
    "    i=0\n",
    "    pos_mask = np.zeros(np.shape(embeddings)[1]+1)\n",
    "    pos_mask[0] +=1\n",
    "    #adding 1 at start : this is target (1 is for happy emoji, 0 or -1 for sad face)\n",
    "    training_set_pos = np.zeros(((np.shape(pos_train)[0],np.shape(embeddings)[1]+1))) + pos_mask\n",
    "    training_set_neg = np.zeros(((np.shape(neg_train)[0],np.shape(embeddings)[1]+1)))\n",
    "    vocab = open('data/vocab_cut.txt')\n",
    "    #for each word, search if it is in pos_train or neg_train\n",
    "    for word_ in vocab:\n",
    "        word = word_.split(\"\\n\")[0]\n",
    "        current_emb = embeddings[i]\n",
    "        for j in range(0,np.shape(pos_train)[0]):\n",
    "            #if yes, add its embeddings.\n",
    "            if word in pos_train[j]:\n",
    "                training_set_pos[j,1:np.shape(embeddings)[1]+1] += current_emb\n",
    "        for j in range(0,np.shape(neg_train)[0]):\n",
    "            if word in neg_train[j]:\n",
    "                training_set_neg[j,1:np.shape(embeddings)[1]+1] += current_emb\n",
    "        i+=1\n",
    "    #then divide by number of words (averaging word vector over all words of the tweet)\n",
    "    for i in range(0,np.shape(embeddings)[1]):\n",
    "        training_set_pos[:,i+1] = training_set_pos[:,i+1]/word_nbr_per_tweet_pos\n",
    "        training_set_neg[:,i+1] = training_set_neg[:,i+1]/word_nbr_per_tweet_neg\n",
    "    np.save(str('data/trainingset_pos')+flag_save, training_set_pos)\n",
    "    np.save(str('data/trainingset_neg')+flag_save, training_set_neg)\n",
    "    \n",
    "def test():\n",
    "     for subdir, dirs, files in os.walk('embeddings'):\n",
    "        for file in files:\n",
    "            print(file)\n",
    "            assert 0==1\n",
    "            construct_features(\"embeddings/\"+file)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "216 results found.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAEGCAYAAABmXi5tAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHTJJREFUeJzt3X1wJHd95/H3V44dKYuxk5jsnWS8UuTYxgHjOMfGd6Eq\nWsjGaycB8lBByyrHAiGUDra4y/luzdVNzU4pVcHElwNsSgkVkw3xgpIATkySC+iOiJTjLDbx45H1\nA2K0PiSXebLv8EYixvu9P6ZHO5qdh25NT/d09+dVpdp56Pn1d7S//m7vr3+/b5u7IyIi+TeUdgAi\nIpIMJXwRkYJQwhcRKQglfBGRglDCFxEpCCV8EZGCSDzhm9ntZva0mT0cYtvfMbMHzOx+M3vMzL6V\nRIwi26G+LYPOkp6Hb2avBp4DPuruV0X43LuAq9391/oWnEgP1Ldl0CV+hu/udwPPNL5mZj9sZv/D\nzO4zs8+b2WUtProf+HgiQYpsg/q2DLrvSTuAwIeBd7j7spntBuaB19bfNLNLgHHgc+mEJ7Jt6tsy\nMFJP+Ga2A/g3wJ+amQUvn9u02TTwCVcdCMkQ9W0ZNKknfGrDSs+4+zUdtpkG/l1C8YjERX1bBkpa\n0zIt+MHdvw1UzeyXN980u6rh8RXAhe5+PPEoJde6zaoxs8vN7B4z2zCz3wjbLOrbMqDSmJb5MeAe\n4DIze9LM3gIcAN5mZg+a2f8GXtfwkTcCC0nHKYXwB8B1Hd7/JnAI+O0wjalvy6BLfFqmyCAxs13A\npztNozSzMvBtd/+d5CITiZ9W2oqIFIQSvohIQSQ6S8fMNH4kfeXu1n2r+KlvS7/F0bfTWGnb8adc\nLnfdJsyP2slOO3HFsk2bs2pCbNdT3x6U39Mg7Ccv+0hqP3EZhHn4IqkIZtVMAT9oZk8CZeA8wN39\nw2a2E/gicD5w2szeDVzp7s+lFbNIL5TwpbDc/U1d3n8aeGlC4Yj03cBdtJ2amlI7BWsnrljyLqnf\nUxL7ycs+ktxPHBKdh29mnuT+pFjMDE/xoq36tvRLXH174M7wRUSkP5TwRUQKQhdtRQbcykqV+fkS\nGxurDA+PMTs7x/j4RNphSQZpDF9yI49j+CsrVcrlvUxPLzMyAuvrsLAwSaWyqKRfIBrDFymA+fnS\nZrIHGBmB6ell5udL6QYmmaSELzLANjZWN5N93cgIbGyspROQZFrXhN+nm0SISAjDw2Osr299bX0d\nhodH0wlIMi3MGX6sN4kQkfBmZ+dYWJjcTPr1MfzZ2bl0A5NMCnXRNq6bROiirfRTHi/aQuMsnTWG\nh0c1S6eA4urbmpYpMuDGxye4+eY70g5DckAXbUVECiLxM/wjR45sPp6amspU4SEZLEtLSywtLaUd\nhkhmhB3DH6c2hv+KDtuUgefc/b912EZj+NI3eR3DF4mrb3dN+I03iQCepstNIoDnaHOTCB0U0k9K\n+JJXiSX8OOmgkH5Swpe8UmkFERGJRAlfRKQglPClsLqVDQm2+aCZPWFmD5rZ1UnGJxI3JXwpso5l\nQ8zsemDS3X8EeAfwu0kFJtIPuVtpe7Ja5WipxOnVVYbGxjg4N8euCS1Dl7O5+91B2ZB2Xg98NNj2\nC2Z2gZntdPenk4lQJF65Svgnq1Vu3buXyvIyO4BTQPn4cQ4tLirpy3aMAf+n4flq8JoSvmRSroZ0\njpZKm8keYAdQWV7maEk3ixARydUZ/unV1c1kX7cDOL2mm0XItqwCL214fnHwWksqGyJx6VfZkFwl\n/KGxMU7BlqR/Chga1c0ipC0Lflq5C3gn8Mdmdi3wbKfx+8aEL9KL5hOGSqUSS7u5Wmnbcgx/clJj\n+AURdTVit7IhwTa3Afuodae3uPv9bdrSSlvpG5VWaGNzls7aGkOjo5qlUyAqrSB5pYQv0kQJX/JK\ntXRERCQSJXwRkYJQwhcRKQglfBGRglDCFxEpCCV8EZGC6JrwVTNcRCQfwpzhq2a4iEgOdE347n43\n8EyHTbbUDAcuMLOd8YQnIiJxiWMMv13NcBERGSC6aCsiUhBxlEdWzXBJRb9qhovkVajiaWY2Dnza\n3V/R4r0bgHe6+88GNcPf7+7XtmlHBaakb1Q8TfIqrr7d9Qy/sWa4mT1JU81wd/8rM7vBzL5MUDO8\n16BERCR+Ko8suaEzfMkrlUcWEZFIlPBFRApCCV9EpCCU8KWwzGyfmT1qZo+b2eEW719oZp8ys4fM\n7LiZXZlGnCJxUcKXQjKzIeA2anWifhTYb2ZXNG32X4AH3P2VwJuBDyYbpUi8lPClqHYDT7j7SXd/\nHligVheq0ZXA5wDc/TFg3MxekmyYIvFRwpeiaq4B9VXOrgH1EPCLAGa2G7iE2kpykUyKo7SCSF69\nF/iAmd0PPAI8ALzQbmOVDZG49KtsiBZeSW5EWZwSlAE54u77guc3UVs9fnOHz1SBV7j7cy3eU9+W\nvtHCK5He3Adcama7zOw8YBq4q3EDM7vAzM4NHr8d+HyrZC+SFRrSkUJy9xfM7F3AZ6md+Nzu7ifM\n7B0EdaKAlwF/aGangS8Bb0sj1pWVKvPzJTY2VhkeHmN2do7x8Yk0QpGM05CO5EYea+msrFQpl/cy\nPb3MyAisr8PCwiSVyqKSfoFoSEekAObnS5vJHmBkBKanl5mfL6UbmGSSEr7IANvYWN1M9nUjI7Cx\nsZZOQJJpSvgiA2x4eIz19a2vra/D8PBoOgFJpinhiwyw2dk5FhYmN5N+fQx/dnYu3cAkk3TRVnIj\njxdtoXGWzhrDw6OapVNAcfVtJXzJjbwmfBHN0hERkUhCJXzVDRcRyb6uCV91w0VE8iHMGb7qhouI\n5ECYhK+64SIiORBX8bTQdcNVM1zi0q+a4SJ51XVaZpx1wzV1TfpJ0zIlr5Kclqm64SIiOdB1SCdL\ndcMBTlarHC2VOL26ytDYGAfn5tg1oVWJIiK5Wml7slrl1r17qSwvswM4BZQnJzm0uKikXwAa0pG8\n0krbFo6WSpvJHmAHUFle5mhJtcNFRHKV8E+vrm4m+7odwOk11Q4XEclVwh8aG+NU02ungKFR1Q4X\nEclVwj84N0d5cnIz6dfH8A/OqXa4nC1EjagXm9ldZvagmT1iZgdTCFMkNrm6aAsNs3TW1hgaHdUs\nnQKJcmErqBH1OPBaYI3a9ONpd3+0YZv3AC929/eY2UXAY8BOd/9ui/Z00Vb6Jq6LtnGttB0YuyYm\nKN9xR9phyODbrBEFYGb1GlGPNmzjwPnB4/OBb7ZK9iJZkashHZEIwtSIug240szWqNWLendCsYn0\nRe7O8EVidB21st+vMbNJYNHMrmq3ilx1oiQu/aoTlbsxfCmuiGP4XWtEmdlfAL/l7n8XPP9fwGF3\n/2KL9tS3pW+08EqkN11rRAEngZ8GMLOdwGXAVxKNUiRGGtKRQgpZI+o3gaNm9nDwsf/s7t9KKWSR\nnmlIR3JDtXQkrzSkIyIikSjhi4gUhBK+iEhBKOGLiBSEEr6ISEFoWqaI5MrKSpX5+RIbG6sMD48x\nOzvH+LgKKELIM3yVkRWRLFhZqVIu72Vq6hi/8AtLTE0do1zey8pKNe3QBkLXefhxlpHVXGXpJ83D\nl8OHZ5iaOsbIyJnX1tdhaekAN9+c3Sq6Sc7D3ywj6+7PA/Uyso1URlZEUrexsbol2QOMjMDGhm5z\nCuESvsrIikgmDA+Psb6+9bX1dRge1m1OIb6LtqHLyKqErMSlXyVkJbtmZ+col48zPb3MyEgt2S8s\nTFKp6DanEG4MP7YyshrnlH7SGL5A4yydNYaHR3MxSyeuvh0m4Z9D7SLsa4GngHuB/e5+omGbDwFf\nc/dKUEb2i8ArmysL6qCQflLCl7xK7J62KiMrIpIPKo8suaEzfMkrlUcWEZFIlPBFRApCCV9EpCCU\n8EVECkIJPyNOVqtUZmYo79lDZWaGk1UVg+pViKKAN5rZA2Z2f1AU8LtmdmEasYrEQbN0MuBktcqt\ne/dSWV5mB3AKKE9OcmhxkV0T2V5QEqcoMxnCFAVs2v7ngH/v7j/d5n31bekbzdIpkKOl0mayB9gB\nVJaXOVoqpRlW1oUpCthoP/DxRCIT6RMl/Aw4vbq6mezrdgCn11QBsAdhigICYGYjwD7gkwnEJdI3\nuuNVBgyNjXEKtiT9U8DQqCoAJuTngbvd/dlOG6kwoMSlX4UBNYafARrDDyfiGH7XooAN234K+BN3\nX+jQnvq29E1ixdPipINi+05WqxwtlTi9tsbQ6CgH5+aU7JtETPhdiwIG210AfAW42N3Xz2rozHbq\n29I3SvgiTaIeFGa2D/gAZ4oCvrepKCBm9mbgOnd/U5e21Lelb5TwRZqoeJrklaZliohIJEr4IiIF\noYQvIlIQSvgiIgWhhC8iUhChEr6qCoqIZF/XaZlxVhXU1DXpJ03LlLxKclqmqgqKiORAmISvqoIi\nIjkQd7XMrlUFVVFQ4tKvioIieRVmDD+2qoIa55R+0hi+5FVitXTirCqog0L6SQlf8iquvt11SMfd\nXzCzdwGf5UxVwRPNVQWBNwCf6VRCVkSk31ZWqszPl9jYWGV4eIzZ2TnGx1VKHFQtU3JEZ/iyslKl\nXN7L9PQyIyOwvg4LC5NUKouZTvqqliki0mR+vrSZ7AFGRmB6epn5+VK6gQ0IJXwRyY2NjdXNZF83\nMgIbG2vpBDRglPBFJDeGh8dYb7qKuL4Ow8Oj6QQ0YJTwRSQ3ZmfnWFiY3Ez69TH82dm5dAMbELpo\nK7mhi7YCjbN01hgeHs3FLB3d01akyTZvYv5+zkw3brWYcAr478C5wNfdfU+bttS3pW+U8EWaRDko\nwlSBDRYT3gP8jLuvmtlF7v6NNu2pb0vfJLbwSiSnNqvAAphZvQpsY9nvNwGfdPdVgHbJXgaLFl61\np4QvRdWqCuzupm0uA841s78BXgR80N3/KKH4ZBtaLbwql49nfuFVXJTwRdr7HuAa4DXADuDvzezv\n3f3LrTZWJdj0dVp4dfPNd6QbXAT9qgSrhC9FtQpc0vD84uC1Rl8FvuHuG8CGmf0t8Eqga8KXdORl\n4VXzCUOlUomlXc3Dl6K6D7jUzHaZ2XnANHBX0zZ/DrzazM4xs+8DfgI4gQwsLbzqTAk/I05Wq1Rm\nZijv2UNlZoaT1WraIWWau78A1KvAfglYqFeBNbNfD7Z5FPgM8DBwHPiwu/9jWjFLd1p41ZmmZWbA\nyWqVW/fupbK8zA7gFFCenOTQ4iK7JnQhqk4LrwS08KpjO0r4g68yM8ONx46xo+G1U8AtBw5QviM7\nF6L6TQlf8krlkQvk9OrqlmQPtSkjp9eydSFKRNKlWToZMDQ2xik46wx/aFQXokTSksUFXhrSyQCN\n4YejIR1JStJ31kp0DD+uIlM6KLbvZLXK0VKJ02trDI2OcnBuTsm+iRK+JOXw4Rmmpo5tmfO/vg5L\nSwf6ssArsVo6QZGp22goMmVmf96iyNSHaCgy1WtgstWuiQldoBUZEFld4BVmDF9FpgbA5hn+6ipD\nY2M6wxdJUX2BV/MZ/qAv8AozS6dVkamxpm0uA37AzP7GzO4zs1+NK0A5M4Z/47FjVJaWuPHYMW7d\nu1eLr0RSktUFXnFNy6wXmboe2AeUzOzSmNouvKOl0uYFW6jN1qksL3O0VEozLJHCGh+foFJZZGnp\nAHfeuYelpQOZqMgZZkgn1iJTqigYnebht9avioKSbUlNlxwfn8hUBU4IMUvHzM4BHqN20fYp4F5g\nv7ufaNjmCuBWamf33wt8AXhjc90RzWTYHq20DUezdCTp6ZJJSWylrYpMpe/g3BzlyUlOBc/r8/AP\nzg32eKFI0jrVw5eQK23d/a+By5te+72m57cAt8QXmtTtmpjg0OIitzTMwz+kWToiZ8nqdMmkqLRC\nRmgevkh3WZ0umRQVTxOR3MjqdMmkqJaO5IYu2gqoHn7HdpTwiyXPK3aV8CWvlPAlsrxX3VTCl7zS\nDVAkMq3YFcmWlZUqhw/PxNaeEn6BaMXuVma2z8weNbPHzexwi/d/ysyeNbP7g5//mkacUkz1RWRT\nU8dia1PTMgtEd846I0zZ78DfuvvrEg9QCq95EVkcdIZfIFqxu8Vm2W93fx6ol/1ulso1AZFWi8h6\npTP8jIhjdo1W7G7Rquz37hbb/Wsze5BawcD/pJIhkpRWi8h6pYSfAS1n1xw/vq3ZNVqxG8k/AJe4\n+z+Z2fXAn1G790NLqgQrcVlaWuI73/lBbrrp+3n5y5+JrV1Ny8wAVcsMJ8rUNTO7Fjji7vuC5zcB\n3up+zQ2fqQI/7u7favGe+rbErr6I7H3vO6ZpmUWh2TV9cR9wqZntMrPzgGngrsYNzGxnw+Pd1E6Q\nzkr2Iv0Sd819DelkgGbXxM/dXzCzetnvIeD2etnv2tv+YeCXzWwWeB5YB96YXsQivdOQTgbkfYVs\nXLTSVpKU1J21QKUVCmdzlk4wuyZPNXDiooQvSUn6zlpK+CJNlPAFkjnzPnx4hqmpY2fV3V9aOtCX\n+9zG1bc1hi8iudHqzLtcPh77mXdW76wVapaOao5Is5PVKpWZGcp79lCZmeFktZp2SCKJ3dO2viiq\nURburNX1DF81R6RZnAvBROKU1Jn37Owc5fLxFmP4g12mJMwZvmqOyBYqsyyDKqkz7/HxCSqVRZaW\nDnDnnXtYWjrQtwu2cQozhq+aI7KFFoLJoEryzDvuRVFJiOuibaSaI5JtWggmg6p+5t14T9tKJfv3\ntI1L12mZcdYcMTMvl8ubz1VgKpsGZSHY0tISS0tLm88rlYqmZUouJTYP38zOAR6jdtH2KeBeYL+7\nn2jYZqe7Px083g38ibuPt2hLB0VODOJCMM3Dl7xKdOGVme0DPsCZmiPvbaw5YmbvBBprjvwHd/9C\ni3Z0UEjfKOFLXmmlrUgTJXzJG5VHlp5owZRINugm5gUWxy0OtWBKJDv6cRNzJfwMiCtRt1swdUup\npDtniQyYftzEXEM6GRDXylYtmBLJjlarhnulhJ8BcSXq+oKpRlowJTKYZmfnWFiYjDXpK+FnQFyJ\n+uDcHOXJyc226gumDs4NdsEnkSJqrNcTF03LzIA4V7YO4oKpuESdlhmsL3k/Z9aXtFw9bmavAu4B\n3ujun2qzjfp2wegWh912poNi2/KcqOMS5aAIyn4/TkPZb2C6uex3sN0itQWFH1HCF9AtDsPtTAeF\n9FHEhH8tUHb364PnLWtEmdm7gX8GXgX8hRK+QHZvcagxfCmqVmW/xxo3MLNR4A3uPo/u9yANcn2L\nQ5GCej/QeEtPJX0BcnyLQ5FW4lj5m7JV4JKG5xcHrzX6V8CCmRlwEXC9mT3v7ne1avDIkSObj1X6\nO9/6faOV5tLfcdEYvkQ2KPXwm0Ucw+9a9rtp+z8APq0xfKk7M0undqMVzdJp3pkOilyozMxw47Fj\nZ93x6pYDB1It0bDNaZlty343bfsRdNFWUhJXwteQjkSWlxIN7v7XwOVNr/1em23fmkhQIg3q/4uI\niy7aSmQq0SDSf/0oj6yEL5GpRINI/6k8sgyEXRMTHFpc5JaGlb+HsjdLR2Sg9aM8cqiEH2fNEUlX\nXNMpd01MqIa+SB/V5/rHmfS7ztKJs+aIZjKka1CnU8ZF97SVPGms13PDDSRWWmE38IS7n3T354EF\n4PUttjsEfAL4Wq9BSX/EdSMVEem/fpRHDpPwVXMkJ/IynVKkKMbHJ2ItxhbXLB3VHMkATacUKbYw\nF21jrTmieiPpOTg3R/n48bPH8DM6nbJf9UZE8irMRdvYao7owlb68nwjFV20lbxKtJZOXDVHdFBI\nPynhS16peJqkahDLIyvhS14p4UtqBnU+vxK+5JVucSip0Xx+kWxSwpfINJ9fJJuU8CUyzecXySYl\nfIlM5ZFFskkXbWVbBnE+vy7aSl5plo5IEyV8ySvN0hHpkZntM7NHzexxMzvc4v3XmdlDZvaAmd1r\nZj+ZRpwicRm4hB9XbRS1k5120qiHE9y/4TbgOuBHgf1mdkXTZv/T3V/p7j8GvA34/YTD3CKp31MS\n+8nLPpLcTxyU8NVO6u2kdMB0vc+Du/9Tw9MXAacTjO8seUpgedlHkvuJw8AlfJGEdL3PA4CZvcHM\nTgCfBt6aUGwifaGEL9KBu/+Zu78MeAPwm2nHI9KLxGfpJLYzKaSwMxnM7FrgiLvvC57fVPu439zh\nM8vAq9z9Wy3eU9+Wvopjlk6YG6DEJq0pcyIt3Adcama7qN3nYRrY37iBmU26+3Lw+BrgvFbJHtS3\nJRsSTfgig8LdXzCzdwGf5cx9Hk403efhl8zs3wL/DKwDv5JexCK9S3RIR0REUuTuif0A+4BHgceB\nwy3evxF4ALgfeAT4LnBh02e/Cnxtm22sAA8F7z/WJZYXA3cBDwbtHGzzPW7voZ0o8VwIfCrY/jhw\n5Tbj6dROYzxfB54GHu7w9/lB4Ingu13dIp7/C3w7Qhs/tp1YgMuBe4AN4Dei9LmE+mzXffe4n8bf\n1b097CNsn2/7XXrcR6jvEXI/YY+XXr5L2GOp09/J7Z36dsjjLHTfjtT5e/mh9t/mLwO7gHOD4K/o\nsP3PUVv40vjZ8eDPLwEvj9JG8PwrwPeHiQV4D/BbweOLgG9SGwJr/Ox5wHeA10RtZxvxvA8oBY8v\nb/G7CRtPy3Ya4wkevxq4ul1HBK4H/jJ4/BPA8Rbx/BS1f8gei9LGNmK5CPhxYI6GhB+1z/Wpz3b9\nbC/7af5d9fJd2vXVsPH1so+w3yPCfsIcL71+l1DHUpfvEsdxFrpvJzkts+tClyb7gY83fhb4F8Gf\nfwT8bMQ2AIzaLypMLA6cHzw+H/imu3+38bPANdT+JX/VNtqJGs+VwOcA3P0xYNzMXrKNeNq10xgP\n7n438AztvR74aLDtF4ALzGxn03f5PHAntbO6KG1EisXdv+Hu/0DtrLdR1D7XrOc+G/KzvewHGn5X\nPX6Xrn2+S3y97CPs9wi7n67HSwzfJdSx1ElMx1novp1kwg+10AXAzEao/Xflk02frf9Z/2yUNqDW\n2RaBO2DLPTxatXMbcKWZrVH7r9m7W3yPMWC14bNR2okaz0PALwbfbTdwCXDxNuJp185mPGZ2n5m9\nnc7a/X02v/4UtTOQMG00xh4llqgxxv75Dn02zL572Q+E+12F2UeYPt8pvl72EfZ7hN1PmOOl1+8S\n17HUSdjjLFTfHtRZOj8P3O3uz8bcxk+6+1Nm9hbgt83s1cG/sK1cBzzg7q8xs0lqf3lXbSOOlu24\n+3MR43kv8AEzq4/hPgC8sI14OrVTj+cl1P4hajkFsY24pyX2Eksa4uiz293Plt+VmZ3o0I86iavP\nR95H0/HQ6/eA+I6X7e4jzu/SqKfjLMkz/FVq/wLWXRy81so0W//LWv9s/c/6Z6O0gbs/FTw8Qe2/\nUbs7xPIWahdk8Npc7CpwRdP3qJ+R1j8bpZ1I8bj7t939re5+jbu/GfghauOEkeLp0M5mPO7+dWpD\nMVfT3irw0obn9X01/z3/S+D5iG1EjaVTjGH7XK+fb9dnw3y2l/20+l3tbvG5MPsI0+c7xdfLPsJ+\nj1D7CXm89PRdIh5L7b5LN2GPs3B9u9sgf1w/wDlsvbj4IPCyFttdQO1CzkiLz05w5qLtVRHb+D7g\nRcHj86nNq55pFwvwIaAcPN5J7b9PP9D0PYapXSR97TbaiRrPBcC5weO3A0db/F7DxNOuncZ4dgB/\nB/wq8Eibv88bOHMx6VrOXExq/nv+R+DxiG1EiqWhvTLwH6P2uT732a777nE/rX5XP7OdfXToq2Hj\n62Ufob5HhP2EOV56/S5RjqWW3yXYZpzej7NQfTuxhB8EuY/arI0ngJuC194B/HrDNm8GPtbhs6vU\npulFaoPaPxYPUvtv1yPARzrFQu3M9DPAw8HP/jbfY1vtbCOea4P3TwCfAC7YZjwt22kRz4PAGrV/\nQJ6kdmbW/Hu+Leh0DwHXtIjn/wU/kdqIGgtnEsez1IZ+nuTMAXdWn0uhz3bd93b30+J31XY/3fZB\n+D4f+z6ifI+Q+wl7vPTyXcIeS5328TF6P85C920tvBIRKQhVyxQRKQglfBGRglDCFxEpCCV8EZGC\nUMIXESkIJXwRkYJQwhcRKQglfBGRgvj/GpiYufLPhv0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1be5507e470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fix_param(data,idx,value):\n",
    "    assert ((data[:,idx]==value).any())\n",
    "    newdata = []\n",
    "    for i in range(0,np.shape(data)[0]):\n",
    "        if(data[i,idx]==value):\n",
    "\n",
    "            newdata.append(data[i])\n",
    "    #print(newdata)\n",
    "    return recreate_param(newdata)\n",
    "\n",
    "def recreate_param(data):\n",
    "    x = np.shape(data)[0]\n",
    "    y = np.shape(data)[1]\n",
    "    param = np.zeros((x,y))\n",
    "    for i in range(0,x):\n",
    "        for j in range(0,y):\n",
    "            param[i,j] = data[i][j]\n",
    "    return param\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def show_graph():\n",
    "    embedding_dim = [5, 30, 50, 100, 200]\n",
    "    for subdir, dirs, files in os.walk('metadata'):\n",
    "        size = np.shape(files)[0]\n",
    "        losses = np.zeros(size)\n",
    "        names = []\n",
    "        param = []\n",
    "        i=0\n",
    "        for file in files:\n",
    "            f = np.load('metadata/'+str(file))\n",
    "            losses[i] = f\n",
    "            names.append(file)\n",
    "            p = extrac_param(file)\n",
    "            p.append(f)\n",
    "            param.append(p)\n",
    "            i+=1\n",
    "    print(np.shape(names)[0], \"results found.\")\n",
    "    param = recreate_param(param)\n",
    "    fixed_emb = fix_param(param,0,50)\n",
    "    fixed_eta = fix_param(fixed_emb,1,0.01)\n",
    "    xs = fixed_eta[:,2]\n",
    "    ys = fixed_eta[:,3]\n",
    "    zs = fixed_eta[:,5]\n",
    "    plt.figure()\n",
    "    plt.subplot(121)\n",
    "    plt.axis([min(xs)-min(xs)/10,max(xs)+max(xs)/10,min(zs)*0.9,max(zs)*1.1])\n",
    "    plt.plot(xs,zs,'ro')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(xs,zs,'yo')\n",
    "show_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
