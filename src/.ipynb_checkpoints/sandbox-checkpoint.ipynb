{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.linear_model as sk\n",
    "import re\n",
    "from glove_routines import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\:\\'\\)\n",
      "['lol', ' lol', ' lol', ' lol', ' lol', ' lol']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word = \"lol wutwut (8 lol ? <user> lol , quoi ahah lol wutwut lol lol\"\n",
    "smiley = \":')\"\n",
    "print(re.escape(smiley))\n",
    "test = word.split()\n",
    "listesc = \".^$*+?{}[]\\|()\" #list of all escaped charactes\n",
    "if('\\(8' in listesc):\n",
    "    print(\"loel\")\n",
    "pd = \"lol\" \n",
    "if re.search(r\"(?:(?:(?:\\b)|^)\"+pd+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+pd+\"(?:$|(?=\\s)))\",word):\n",
    "    count = re.findall(r\"(?:(?:(?:\\b)|^)\"+pd+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+pd+\"(?:$|(?=\\s)))\",word)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counting ended\n",
      "\\<user\\>\n",
      "\\<user\\> \" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "\\<user\\> <user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "\\<user\\> workin hard or hardly workin rt <user> at hardee's with my future coworker <user>\n",
      "\n",
      "\\<user\\> like dammm <user> lexis u got a lot to say when ur on twitter lol\n",
      "\n",
      "\\!\n",
      "\\! \" <user> just put casper in a box ! \" looved the battle ! #crakkbitch\n",
      "\n",
      "\\! <user> <user> thanks sir > > don't trip lil mama ... just keep doin ya thang !\n",
      "\n",
      "\\! visiting my brother tmr is the bestest birthday gift eveerrr ! ! !\n",
      "\n",
      "\\! <user> yay ! ! #lifecompleted . tweet / facebook me to let me know please\n",
      "\n",
      "\\! <user> #1dnextalbumtitle : feel for you / rollercoaster of life . song cocept : life , #yolo , becoming famous ? <3 14 #followmeplz ! <3 x15\n",
      "\n",
      "\\! we send an invitation to shop on-line ! here you will find everything you need - without leaving home ... <url>\n",
      "\n",
      "\\! <user> agreed ! 12 more days left tho\n",
      "\n",
      "\\! grateful today for a dream fulfilled ! ! my heart is so full - first 3 completed tracks have arrived back from new york ! #yeslord !\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-162-29fe15ba7d5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneg_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[1;31m#if word in neg_train[j]:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mr\"\\s\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\"\\s\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mneg_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mtraining_set_neg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mcurrent_emb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mi\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Max-Pc\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(pattern, string, flags)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[0;32m    172\u001b[0m     a match object, or None if no match was found.\"\"\"\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Max-Pc\\Anaconda3\\lib\\re.py\u001b[0m in \u001b[0;36m_compile\u001b[1;34m(pattern, flags)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;31m# internal: compile pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m         \u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mloc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetlocale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_locale\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLC_CTYPE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    pos_train = open('data/pos_train.txt').readlines()\n",
    "    neg_train = open('data/neg_train.txt').readlines()\n",
    "    embeddings = np.load('data/embeddings.npy')\n",
    "\n",
    "    \n",
    "    #count number of word/tweet and store it for both positive set and negative set\n",
    "    word_nbr_per_tweet_pos = np.zeros(np.shape(pos_train)[0])\n",
    "    for j in range(0,np.shape(pos_train)[0]):\n",
    "        tweet = pos_train[j]\n",
    "        size = len(tweet.split())\n",
    "        word_nbr_per_tweet_pos[j] = size\n",
    "    \n",
    "    word_nbr_per_tweet_neg = np.zeros(np.shape(neg_train)[0])\n",
    "    for j in range(0,np.shape(neg_train)[0]):\n",
    "        tweet = neg_train[j]\n",
    "        size = len(tweet.split())\n",
    "        word_nbr_per_tweet_neg[j] = size\n",
    "    \n",
    "    print(\"counting ended\")\n",
    "    \n",
    "    i=0\n",
    "    pos_mask = np.zeros(np.shape(embeddings)[1]+1)\n",
    "    pos_mask[0] +=1\n",
    "    #adding 1 at start : this is target (1 is for happy emoji, 0 or -1 for sad face)\n",
    "    training_set_pos = np.zeros(((np.shape(pos_train)[0],np.shape(embeddings)[1]+1))) + pos_mask\n",
    "    training_set_neg = np.zeros(((np.shape(neg_train)[0],np.shape(embeddings)[1]+1)))\n",
    "    vocab = open('data/vocab_cut.txt')\n",
    "    #for each word, search if it is in pos_train or neg_train\n",
    "    prevWord =\"\"\n",
    "    for word_ in vocab:\n",
    "        word = word_.split(\"\\n\")[0]\n",
    "        #if charac is ecaped, a special regex is used this is why there is a boolean\n",
    "        if(re.escape(word) != word):\n",
    "            word= re.escape(word)\n",
    "        current_emb = embeddings[i]\n",
    "        for j in range(0,np.shape(pos_train)[0]):\n",
    "            #if yes, add its embeddings.\n",
    "            #if word in pos_train[j]:\n",
    "            if(prevWord != word):\n",
    "                print(word)\n",
    "                prevWord=word\n",
    "            if re.search(r\"(?:(?:(?:\\b)|^)\"+word+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+word+\"(?:$|(?=\\s)))\",training_set_pos[j]):\n",
    "                count = re.findall(r\"(?:(?:(?:\\b)|^)\"+word+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+word+\"(?:$|(?=\\s)))\",training_set_pos[j])\n",
    "                if(j < 20):\n",
    "                    print(word,pos_train[j])\n",
    "                training_set_pos[j,1:np.shape(embeddings)[1]+1] += count*current_emb\n",
    "        for j in range(0,np.shape(neg_train)[0]):\n",
    "            #if word in neg_train[j]:\n",
    "            if re.search(r\"(?:(?:(?:\\b)|^)\"+word+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+word+\"(?:$|(?=\\s)))\",training_set_neg[j]):\n",
    "                count = re.findall(r\"(?:(?:(?:\\b)|^)\"+word+\"(?:(?=\\b)|$)|(?:^|(?:\\s))\"+word+\"(?:$|(?=\\s)))\",training_set_neg[j])\n",
    "                training_set_neg[j,1:np.shape(embeddings)[1]+1] += count*current_emb\n",
    "        i+=1\n",
    "        if(i%5000 ==0):\n",
    "            print(\"5000 done\")\n",
    "    #then divide by number of words (averaging word vector over all words of the tweet)\n",
    "    for i in range(0,np.shape(embeddings)[1]):\n",
    "        training_set_pos[:,i+1] = training_set_pos[:,i+1]/word_nbr_per_tweet_pos\n",
    "        training_set_neg[:,i+1] = training_set_neg[:,i+1]/word_nbr_per_tweet_neg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab = \"\"\n",
    "for word_ in vocab:\n",
    "        word = word_.split(\"\\n\")[0]\n",
    "        #if charac is ecaped, a special regex is used this is why there is a boolean\n",
    "        escaped = False\n",
    "        listesc = \".^$*+?{}[]\\|()\" #list of all escaped charactes\n",
    "        if(word in listesc):\n",
    "            word= re.escape(word)\n",
    "            escaped = True\n",
    "        current_emb = embeddings[i]\n",
    "        for j in range(0,np.shape(pos_train)[0]):\n",
    "            #if yes, add its embeddings.\n",
    "            #if word in pos_train[j]:\n",
    "            if(prevWord != word):\n",
    "                print(word)\n",
    "                prevWord=word\n",
    "            if(escaped):\n",
    "                boole = re.search(r\"\"+word,pos_train[j]) #regex if escaped character\n",
    "            else:\n",
    "                boole = re.search(r\"\\b\"+word+\"\\\\b\",pos_train[j])\n",
    "                if boole:\n",
    "                    if(j < 20):\n",
    "                        print(word,pos_train[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
